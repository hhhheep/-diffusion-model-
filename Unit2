fine tuning的意思是 重一个类似的任务的模型中 迁移过来
经过几轮训练后，使得旧的模型可以学会现有的资料

当然任务不相同时就可能需要更多的资料才能学的好

在diffusion model 我额外学会的是  通过加入额外的loss function 可以控制模型的输出

**fine-tuning**

diffusion model的 find tuning 有点不同 他需要将噪声从复杂一直到简单的噪声
这个噪声依旧由随机产生


在预训练前  首先还是要对资料进行处理，改变图像大小 旋转 标准化
我在这里发现了 unet需要的 GPU容量很大 我调小了 batch和img size




**Guidance**
color loss function
通过对某种颜色的指定 减少模型对这种颜色的偏差 来指定模型最终生成的颜色是什么


Variant 1: shortcut method（变体1：快捷方法）

在这个变体中，首先设置了x.requires_grad属性，然后进行模型的前向传播，包括预测噪声残差（noise_pred）和获取预测的x0。
接着，计算损失并获取梯度，然后根据梯度修改输入x。最后，通过时间步执行模型步骤，以得到新的输入x。

其中 在这个变体中，x.requires_grad属性是在预测噪声残差之后、计算损失之前设置的。
这意味着模型的前向传播中不计算x的梯度，只有在计算损失之后，根据损失来计算梯度并修改x
这个变体使用了一个“快捷”方法，即通过在损失计算之后设置x.requires_grad，以允许在下一步迭代中计算梯度。

Variant 2: setting x.requires_grad before calculating the model predictions（变体2：在计算模型预测之前设置x.requires_grad）

这个变体与Variant 1 类似，但它在计算模型预测之前设置了x.requires_grad属性。首先，设置x.requires_grad属性，
然后进行模型的前向传播，包括预测噪声残差和获取预测的x0。接着，计算损失并获取梯度，然后根据梯度修改输入x。
最后，通过时间步执行模型步骤，以得到新的输入x。

在这个变体中，x.requires_grad属性是在模型的前向传播之前设置的。
这意味着在模型的前向传播中，包括预测噪声残差和获取预测的x0，都会计算x的梯度。
设置x.requires_grad属性的时机早于变体1，它在模型的前向传播之前就已经生效，允许梯度计算。

prompt

clip方法 是一个将文字和图片结合起来的，找出 文字和图片的相关性
在这里可以用文字指导图片生成






